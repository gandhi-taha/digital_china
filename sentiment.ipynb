{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-kTyd2Csefwx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import jieba\n",
        "import re\n",
        "import csv\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HExDObK6efwy"
      },
      "outputs": [],
      "source": [
        "# 我们使用tensorflow的keras接口来建模\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWljodwgSX_d",
        "outputId": "4e576a9b-6517-4dbb-d1cb-7159455bfd32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab Notebooks/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDCZyL_zSuIH",
        "outputId": "83a21b2d-11b4-4e9d-b517-6bdc4a131169"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "!bzip2 -d sgns.zhihu.bigram-char.bz2"
      ],
      "metadata": {
        "id": "KWdoXX1HGbRu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vxj2l6HCefwz"
      },
      "outputs": [],
      "source": [
        "embedding = KeyedVectors.load_word2vec_format('sgns.zhihu.bigram-char', binary=False, unicode_errors=\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hYj6rMWMefwz"
      },
      "outputs": [],
      "source": [
        "#embedding维度300\n",
        "embedding_dim = embedding['中国'].shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fcFdfxOJefwz",
        "outputId": "d7238d9e-0926-4602-be9d-cb02340133f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5562877"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "embedding.similarity('中国','美国')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GjMlrEhbefwz",
        "outputId": "00b27988-056a-4a57-8bed-a4409f648e29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Index: 51\n"
          ]
        }
      ],
      "source": [
        "word_index = embedding.key_to_index['中国']\n",
        "print(\"Word Index:\", word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0RQ1QtV8efwz",
        "outputId": "d2119219-286f-464d-f1a7-292c53ae5538",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('中国人', 0.5616261959075928),\n",
              " ('美国', 0.5562876462936401),\n",
              " ('我国', 0.531586766242981),\n",
              " ('全中国', 0.5306392908096313),\n",
              " ('中国茶', 0.5249154567718506),\n",
              " ('中国海', 0.5224687457084656),\n",
              " ('中国武协', 0.5200953483581543),\n",
              " ('外国', 0.5197730660438538),\n",
              " ('中国篮球', 0.5111113786697388),\n",
              " ('日本', 0.5098268389701843)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "embedding.most_similar(positive=['中国'], topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file with semicolon delimiter\n",
        "file_path = 'zhihu_cm_data.csv'  # Replace with your file path\n",
        "data = pd.read_csv(file_path, delimiter=';', encoding='utf-8', on_bad_lines='skip')\n",
        "\n",
        "# Extract relevant columns\n",
        "train_text_orig = data['content'].tolist()\n",
        "train_target = data['author_gender'].astype(int).tolist()\n",
        "\n",
        "# Print the number of examples\n",
        "print(f\"{len(train_text_orig)} text examples in trainset\")\n",
        "\n",
        "# Prepare the DataFrame for saving\n",
        "prepared_data = pd.DataFrame({\n",
        "    'text': train_text_orig,\n",
        "    'label': train_target\n",
        "})\n",
        "\n",
        "# Save to a new CSV file\n",
        "output_file_path = 'zhihu_prepared_data.csv'  # Specify the desired file path and name\n",
        "prepared_data.to_csv(output_file_path, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"Processed data has been saved to {output_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWRSSNM2Jwbk",
        "outputId": "e5fdbf00-8474-4196-9906-61c0d62c194f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "960 text examples in trainset\n",
            "Processed data has been saved to zhihu_prepared_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "STGaK84Defw0",
        "outputId": "9db20786-0c83-40d1-bc7b-5114448fdcc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "960 text examples in trainset\n"
          ]
        }
      ],
      "source": [
        "train_text_orig = []\n",
        "train_target = []\n",
        "\n",
        "csv_orig = csv.reader(open('zhihu_prepared_data.csv'))\n",
        "next(csv_orig, None)\n",
        "for line in csv_orig:\n",
        "    # Swap the columns\n",
        "    train_text_orig.append(line[0])\n",
        "    train_target.append(line[1])\n",
        "\n",
        "train_target = np.array(train_target).astype('int')\n",
        "print('%d text examples in trainset' % len(train_text_orig))\n",
        "# ...existing code..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "k5YNhVWbefw0"
      },
      "outputs": [],
      "source": [
        "#convert to onehot\n",
        "train_target = to_categorical(train_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "l8lAnMMVefw0"
      },
      "outputs": [],
      "source": [
        "#清晰数据\n",
        "def clean_text(text):\n",
        "    text = re.sub(\"<[^>]+>\", \"\", text)\n",
        "    text = text.replace(\"&nbsp;\", \"\")\n",
        "    text = text.replace(\"\\n\", \"\")\n",
        "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）-]+\", \"\", text)\n",
        "    text = re.sub(\"[^0-9A-Za-z\\u4e00-\\u9fa5]\", \"\", text)\n",
        "    text = re.sub( \"\\\\(.*?\\\\)|\\\\{.*?}|\\\\[.*?]\", \"\", text)\n",
        "    return text\n",
        "\n",
        "def tokenize_text(text):\n",
        "    words = [w for w in jieba.cut(text)]\n",
        "    embedding_vectors = []\n",
        "    for idx, word in enumerate(words):\n",
        "        try:\n",
        "            embedding_vectors.append(embedding.vocab[word].index)\n",
        "        except KeyError:\n",
        "            embedding_vectors.append(0)\n",
        "    return embedding_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "v8HmLLkzefw0"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(text, model):\n",
        "    tokens = []\n",
        "    for word in text.split():\n",
        "        if word in model.key_to_index:  # removed .wv\n",
        "            tokens.append(word)\n",
        "    return tokens\n",
        "#tokenize\n",
        "train_tokens = []\n",
        "model = w2v_model = embedding\n",
        "for text in  train_text_orig:\n",
        "    pure_text = clean_text(text)\n",
        "    tokens = tokenize_text(pure_text,model)\n",
        "    train_tokens.append(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ojcKdzxyefw0",
        "outputId": "9755c59a-86e1-4c6f-c274-959e7c046e7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00625\n"
          ]
        }
      ],
      "source": [
        "#平均token数\n",
        "\n",
        "if train_tokens:\n",
        "    num_tokens = [len(tokens) for tokens in train_tokens]\n",
        "    print(np.mean(num_tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "N60BfR2Xefw0",
        "outputId": "289cb5c1-36c1-4dd7-809c-a36d967caaec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
        "max_tokens = int(max_tokens)\n",
        "max_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "Z_DG6-AGefw0",
        "outputId": "37c22d97-c820-4133-c0b0-4751ea6906e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# 取tokens的长度为80时，大约 93%的样本被涵盖\n",
        "# 我们对长度不足的进行padding，超长的进行修剪\n",
        "max_tokens = 80\n",
        "np.sum( np.array(num_tokens) < max_tokens ) / len(num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lE-uK6E6efw0",
        "outputId": "b8b52dd4-5c47-482e-83e5-f4c33b339887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# 用来将tokens转换为文本\n",
        "def reverse_tokens(tokens):\n",
        "    text = ''\n",
        "    for i in tokens:\n",
        "        if i != 0:\n",
        "            text = text + embedding.index2word[i]\n",
        "        else:\n",
        "            text = text + ' '\n",
        "    return text\n",
        "\n",
        "reverse_tokens(train_tokens[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "_FtYFbS0efw0",
        "outputId": "a30d0f2d-3d40-4074-f1cb-fd1f904700e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "259753"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "len(embedding.index_to_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "FE-SlZ5sefw0"
      },
      "outputs": [],
      "source": [
        "#取100000/259753个词\n",
        "num_words = 100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "qTdMzRJHefw0",
        "outputId": "21aa8d67-4ebf-40d4-83b6-272a970d4a92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0, 532], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# 进行padding和truncating， 输入的train_tokens是一个list\n",
        "# 返回的train_pad是一个numpy array\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Ensure train_tokens contains only integer indices\n",
        "train_tokens = [[model.key_to_index[word] for word in tokens if word in model.key_to_index] for tokens in train_tokens]\n",
        "\n",
        "# Padding and truncating\n",
        "train_pad = pad_sequences(train_tokens, maxlen=max_tokens, padding='pre', truncating='pre')\n",
        "\n",
        "# Replace out-of-vocabulary words with 0\n",
        "train_pad[train_pad >= num_words] = 0\n",
        "\n",
        "# Check the padded sequence\n",
        "train_pad[20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "lGwufhVUefw0",
        "outputId": "618c9e30-71a7-4047-a6c2-abdf6c7720b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(259753, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# 使用259753个词\n",
        "num_words = 259753\n",
        "embedding_dim = 300\n",
        "# 初始化embedding_matrix，之后在keras上进行应用\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "# embedding_matrix为一个 [num_words，embedding_dim] 的矩阵\n",
        "for i in range(num_words):\n",
        "  embedding_matrix[i, :] = embedding[embedding.index_to_key[i]]  # replaced index2word with index_to_key\n",
        "embedding_matrix = embedding_matrix.astype('float32')\n",
        "np.array(embedding_matrix).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "vKmFKn7Zefw1"
      },
      "outputs": [],
      "source": [
        "# 90%的样本用来训练，剩余10%用来测试\n",
        "X_train, X_test, y_train, y_test = train_test_split(train_pad,\n",
        "                                                    train_target,\n",
        "                                                    test_size=0.1,\n",
        "                                                    random_state=12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "utmAKUKoefw1",
        "outputId": "7543b32a-d81e-4c03-f449-0ef7ee9fc78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │      \u001b[38;5;34m77,925,900\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │      <span style=\"color: #00af00; text-decoration-color: #00af00\">77,925,900</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m77,925,900\u001b[0m (297.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,925,900</span> (297.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m77,925,900\u001b[0m (297.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">77,925,900</span> (297.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(num_words,\n",
        "                   embedding_dim,\n",
        "                   weights=[embedding_matrix],\n",
        "                   input_length = max_tokens,\n",
        "                   trainable = False))\n",
        "model.add(Bidirectional(LSTM(units=64, return_sequences=True)))\n",
        "model.add(LSTM(units=16, return_sequences=False))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "# 我们使用adam以0.001的learning rate进行优化\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "hC6WFncqefw1"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "scrolled": true,
        "id": "cUG0iffJefw1",
        "outputId": "6ce4014f-781a-40dd-c0cf-690102a8431f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8963 - loss: 0.5674 - val_accuracy: 0.9195 - val_loss: 0.2843\n",
            "Epoch 2/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9101 - loss: 0.3044 - val_accuracy: 0.9195 - val_loss: 0.2809\n",
            "Epoch 3/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9111 - loss: 0.3013 - val_accuracy: 0.9195 - val_loss: 0.2825\n",
            "Epoch 4/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.9136 - loss: 0.2956 - val_accuracy: 0.9195 - val_loss: 0.2956\n",
            "Epoch 5/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.9020 - loss: 0.3278 - val_accuracy: 0.9195 - val_loss: 0.2871\n",
            "Epoch 6/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9077 - loss: 0.3095 - val_accuracy: 0.9195 - val_loss: 0.2800\n",
            "Epoch 7/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9125 - loss: 0.2978 - val_accuracy: 0.9195 - val_loss: 0.2816\n",
            "Epoch 8/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9062 - loss: 0.3164 - val_accuracy: 0.9195 - val_loss: 0.2818\n",
            "Epoch 9/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.9059 - loss: 0.3170 - val_accuracy: 0.9195 - val_loss: 0.2799\n",
            "Epoch 10/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - accuracy: 0.9079 - loss: 0.3078 - val_accuracy: 0.9195 - val_loss: 0.2800\n",
            "Epoch 11/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9080 - loss: 0.3077 - val_accuracy: 0.9195 - val_loss: 0.2800\n",
            "Epoch 12/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9042 - loss: 0.3160 - val_accuracy: 0.9195 - val_loss: 0.2828\n",
            "Epoch 13/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 3s/step - accuracy: 0.9103 - loss: 0.3027 - val_accuracy: 0.9195 - val_loss: 0.2857\n",
            "Epoch 14/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.9077 - loss: 0.3104 - val_accuracy: 0.9195 - val_loss: 0.2881\n",
            "Epoch 15/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.9077 - loss: 0.3108 - val_accuracy: 0.9195 - val_loss: 0.2852\n",
            "Epoch 16/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.9120 - loss: 0.2998 - val_accuracy: 0.9195 - val_loss: 0.2816\n",
            "Epoch 17/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2s/step - accuracy: 0.9128 - loss: 0.2962 - val_accuracy: 0.9195 - val_loss: 0.2803\n",
            "Epoch 18/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9047 - loss: 0.3136 - val_accuracy: 0.9195 - val_loss: 0.2800\n",
            "Epoch 19/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.9051 - loss: 0.3131 - val_accuracy: 0.9195 - val_loss: 0.2803\n",
            "Epoch 20/20\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2s/step - accuracy: 0.9116 - loss: 0.3003 - val_accuracy: 0.9195 - val_loss: 0.2800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b7a372aa800>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=num_words, output_dim=embedding_dim, input_length=max_tokens))\n",
        "model.add(LSTM(units=128, return_sequences=False))\n",
        "model.add(Dense(units=2, activation='softmax'))  # Ensure this matches y_train shape\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_split=0.1, epochs=20, batch_size=256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ERO1q5H4efw1",
        "outputId": "47580d3d-01d8-4c75-aa93-99e16b748d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9414 - loss: 0.2256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.23534631729125977, 0.9375]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "model.evaluate(X_test, y_test)\n",
        "#95%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "upuO7K3iefw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da8847c-3ef0-4c27-f24b-87e00ec1cde9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "model.save('if_needed.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "HwTIBFZaefw1"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(text):\n",
        "    pure_text = clean_text(text)\n",
        "    tokens = tokenize_text(pure_text)\n",
        "    tokens_pad = pad_sequences([tokens], maxlen=max_tokens,\n",
        "                           padding='pre', truncating='pre')\n",
        "    # 预测\n",
        "    result = model.predict(tokens_pad)\n",
        "    result_text = ['喜悦','愤怒', '厌恶','低落']\n",
        "    print(result)\n",
        "    print(result_text[np.argmax(result)])\n",
        "    return np.argmax(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "YBzI3Ogtefw1",
        "outputId": "3a2eeb49-81e5-437f-b1d0-0eb1c605c697",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346ms/step\n",
            "[[0.0068893  0.99311066]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "[[0.0068893  0.99311066]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "[[0.0068893  0.99311066]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "[[0.0068893  0.99311066]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "[[0.0068893  0.99311066]]\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the model using a supported file format\n",
        "model = load_model('if_needed.h5')  # Update with your model path\n",
        "\n",
        "def predict_sentiment(text, model):\n",
        "    pure_text = clean_text(text)\n",
        "    tokens = tokenize_text(pure_text, w2v_model)  # pass the model here\n",
        "    tokens_pad = pad_sequences([tokens], maxlen=max_tokens, padding='pre', truncating='pre')\n",
        "    prediction = model.predict(tokens_pad)\n",
        "    return prediction\n",
        "\n",
        "# Example usage\n",
        "print(predict_sentiment(\"品控不好，还没到一个月就坏了\", model))\n",
        "print(predict_sentiment(\"品控不错，挺好的\", model))\n",
        "print(predict_sentiment(\"太开心了\", model))\n",
        "print(predict_sentiment(\"难受啊\", model))\n",
        "print(predict_sentiment(\"谢天牛逼啊\", model))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "g_FK5cAZefw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defc7ddf-dca8-4637-a363-0bcae35b717f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred = [np.argmax(arr) for arr in y_pred]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ieFWkvCSefw1",
        "outputId": "40a2a6cd-82d7-4dd4-a29b-8930eb1bea74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n",
            "96\n",
            "0.9375\n"
          ]
        }
      ],
      "source": [
        "ss = 0\n",
        "for i in range(len(y_pred)):\n",
        "    if(y_pred[i]==np.argmax(y_test[i])):\n",
        "        ss+=1\n",
        "print(ss)\n",
        "print(len(y_pred))\n",
        "print(ss/len(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "Gz4Q8INAefw1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306e3b4a-266f-4e31-b7bf-eb0b2bcb7211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0068893 , 0.99311066]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "predict_sentiment('小米业界良心',model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "KF2Duynlefw6",
        "outputId": "b5bf150c-9ac5-4df9-fd5e-f7bef0b07ae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m300\u001b[0m)             │      \u001b[38;5;34m77,925,900\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m219,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m258\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)             │      <span style=\"color: #00af00; text-decoration-color: #00af00\">77,925,900</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">219,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m78,145,808\u001b[0m (298.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,145,808</span> (298.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,145,806\u001b[0m (298.10 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,145,806</span> (298.10 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#from keras.models import load_model\n",
        "from keras.models import load_model\n",
        "model_loaded = load_model('if_needed.h5')\n",
        "model_loaded.summary()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}